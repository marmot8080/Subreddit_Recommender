{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c4c502",
   "metadata": {},
   "source": [
    "# 단일 분류기 (Single Classifier) 학습\n",
    "\n",
    "계층형 분류기와의 성능 비교를 위해, 모든 서브레딧을 한 번에 분류하는 단일 분류기 모델을 학습합니다. 이 모델은 9개의 서브레딧을 직접적으로 구분하는 작업을 수행합니다.\n",
    "\n",
    "## 학습 과정\n",
    "1.  **데이터 준비**: 전처리된 텍스트 데이터를 `TfidfVectorizer`를 사용하여 고차원 벡터로 변환합니다.\n",
    "2.  **모델 선택**: 선형 모델인 `SGDClassifier`를 기본 분류기로 사용합니다. 이 모델은 대용량 텍스트 데이터에 효율적입니다.\n",
    "3.  **하이퍼파라미터 최적화**: `RandomizedSearchCV`를 이용하여 최적의 하이퍼파라미터를 탐색합니다. 이를 통해 모델의 일반화 성능을 높입니다.\n",
    "4.  **모델 학습 및 평가**: 최적화된 하이퍼파라미터로 모델을 학습시킨 후, 테스트 데이터셋으로 최종 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc45214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: numpy==2.1.3 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 1)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from pandas==2.2.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from matplotlib==3.10.0->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\overl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 2)) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4faaffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27daff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'assets/' \n",
    "MODEL_PATH = 'models/'\n",
    "\n",
    "# 서브레딧 및 그룹 정의\n",
    "SUBREDDITS = [\n",
    "    'Thetruthishere', 'Glitch_in_the_Matrix', 'UnresolvedMysteries',\n",
    "    'learnprogramming', 'cscareerquestions', 'SideProject',\n",
    "    'TrueFilm', 'booksuggestions', 'TrueGaming'\n",
    "]\n",
    "GROUP_MAP = {'Mystery': SUBREDDITS[0:3], 'Dev': SUBREDDITS[3:6], 'Culture': SUBREDDITS[6:9]}\n",
    "VECTOR_DIMENSION = 5000  # 문서 벡터 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371b9606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>preprocessed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thetruthishere</td>\n",
       "      <td>truth leviathan leviathan isnt scary monster a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thetruthishere</td>\n",
       "      <td>streetlight front house turns every time walk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thetruthishere</td>\n",
       "      <td>reflection window seconds behind nearly empty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thetruthishere</td>\n",
       "      <td>strange knocking empty apartment night ive liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thetruthishere</td>\n",
       "      <td>whats unexplainable thing youve ever witnessed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                               preprocessed_content\n",
       "0  Thetruthishere  truth leviathan leviathan isnt scary monster a...\n",
       "1  Thetruthishere  streetlight front house turns every time walk ...\n",
       "2  Thetruthishere  reflection window seconds behind nearly empty ...\n",
       "3  Thetruthishere  strange knocking empty apartment night ive liv...\n",
       "4  Thetruthishere  whats unexplainable thing youve ever witnessed..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = pd.read_csv(FILE_PATH + 'reddit_posts_preprocessed.csv')\n",
    "\n",
    "preprocessed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db41349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 분할 완료: 학습용 7065개, 테스트용 1767개\n",
      "단일 분류기(Single Classifier) 최적화 시작 (RandomizedSearch)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "==================================================\n",
      "최적의 하이퍼파라미터: {'alpha': np.float64(7.068974950624602e-05), 'loss': 'log_loss', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "교차 검증 최고 점수 (Best CV Score): 0.9127\n",
      "--------------------------------------------------\n",
      "최종 테스트 정확도 (Test Accuracy): 0.9106\n",
      "==================================================\n",
      "\n",
      "[상세 분류 리포트]\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Glitch_in_the_Matrix       0.88      0.83      0.85       198\n",
      "         SideProject       0.91      0.95      0.93       189\n",
      "      Thetruthishere       0.81      0.86      0.83       190\n",
      "            TrueFilm       0.97      0.93      0.95       198\n",
      "          TrueGaming       0.96      0.97      0.97       198\n",
      " UnresolvedMysteries       0.98      0.98      0.98       198\n",
      "     booksuggestions       0.96      0.98      0.97       200\n",
      "   cscareerquestions       0.84      0.87      0.86       197\n",
      "    learnprogramming       0.88      0.81      0.85       199\n",
      "\n",
      "            accuracy                           0.91      1767\n",
      "           macro avg       0.91      0.91      0.91      1767\n",
      "        weighted avg       0.91      0.91      0.91      1767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 전체 서브레딧을 대상으로 하는 단일 분류기 학습\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "# 벡터화\n",
    "# NaN 값을 빈 문자열로 대체\n",
    "preprocessed_df['preprocessed_content'] = preprocessed_df['preprocessed_content'].fillna('')\n",
    "preprocessed_df.head()\n",
    "vectorizer = TfidfVectorizer(max_features=VECTOR_DIMENSION, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(preprocessed_df['preprocessed_content']).toarray()\n",
    "\n",
    "# 서브레딧 라벨링\n",
    "y_subreddit = preprocessed_df['subreddit']\n",
    "\n",
    "# 데이터 분할 (Train / Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_subreddit, test_size=0.2, random_state=42, stratify=y_subreddit\n",
    ")\n",
    "print(f\"데이터 분할 완료: 학습용 {X_train.shape[0]}개, 테스트용 {X_test.shape[0]}개\")\n",
    "\n",
    "# RandomizedSearchCV 설정\n",
    "param_dist = {\n",
    "    'loss': ['log_loss'],  \n",
    "    'alpha': loguniform(1e-5, 1e-1),\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "base_model = SGDClassifier(random_state=42, class_weight='balanced', n_jobs=1)\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search_single = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,          \n",
    "    cv=cv_strategy,     \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1,          \n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"단일 분류기(Single Classifier) 최적화 시작 (RandomizedSearch)...\")\n",
    "random_search_single.fit(X_train, y_train)\n",
    "\n",
    "# 결과 출력 및 최종 평가\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"최적의 하이퍼파라미터: {random_search_single.best_params_}\")\n",
    "print(f\"교차 검증 최고 점수 (Best CV Score): {random_search_single.best_score_:.4f}\")\n",
    "\n",
    "# 최적의 모델 추출\n",
    "single_classifier = random_search_single.best_estimator_\n",
    "\n",
    "# 최종 테스트 데이터로 객관적 성능 평가\n",
    "y_pred = single_classifier.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-\" * 50)\n",
    "print(f\"최종 테스트 정확도 (Test Accuracy): {final_accuracy:.4f}\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n[상세 분류 리포트]\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0468da94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일 분류기 모델이 'models/single_classifier.pkl'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 단일 분류기 모델 저장\n",
    "import joblib\n",
    "\n",
    "joblib.dump(single_classifier, MODEL_PATH + 'single_classifier.pkl')\n",
    "print(f\"단일 분류기 모델이 '{MODEL_PATH}single_classifier.pkl'에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
